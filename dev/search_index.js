var documenterSearchIndex = {"docs":
[{"location":"rendering/#Rendering","page":"Rendering","title":"Rendering","text":"","category":"section"},{"location":"rendering/#Camera","page":"Rendering","title":"Camera","text":"","category":"section"},{"location":"rendering/","page":"Rendering","title":"Rendering","text":"Camera is used to cast rays according to its intrinsic and extrinsic parameters. When resizing its resolution it preserves original aspect ratio of focal length since that's the value the model was trained on.","category":"page"},{"location":"rendering/","page":"Rendering","title":"Rendering","text":"Camera\nNerfUtils.set_resolution!\nNerfUtils.shift!\nNerfUtils.rotate!","category":"page"},{"location":"rendering/#NerfUtils.Camera","page":"Rendering","title":"NerfUtils.Camera","text":"Camera(projection, intrinsics::CameraIntrinsics)\n\nCamera maintains original focal length, since the model was trained on a specific value of it, thus we want to preserve the original aspect.\n\nArguments:\n\nprojection::MMatrix{3, 4, Float32}: Camera-to-world projection.\nintrinsics::CameraIntrinsics: Camera intrinsics.\noriginal_focal::SVector{2, Float32}: Original focal length.   Used during camera resizing to preserve original focal length aspect ratio.\noriginal_resolution::SVector{2, UInt32}: Original resolution.   Used during camera resizing to compute scale value   to multiply with original_focal.\n\n\n\n\n\n","category":"type"},{"location":"rendering/#NerfUtils.set_resolution!","page":"Rendering","title":"NerfUtils.set_resolution!","text":"set_resolution!(c::Camera; width::Int, height::Int)\n\nChange resolution of the camera. Preserves original focal length aspect, scaling it instead.\n\n\n\n\n\n","category":"function"},{"location":"rendering/#NerfUtils.shift!","page":"Rendering","title":"NerfUtils.shift!","text":"shift!(c::Camera, relative)\n\nShift camera position by a relative value.\n\n\n\n\n\n","category":"function"},{"location":"rendering/#NerfUtils.rotate!","page":"Rendering","title":"NerfUtils.rotate!","text":"rotate!(c::Camera, rotation)\n\nApply rotation to the camera.\n\n\n\n\n\n","category":"function"},{"location":"rendering/#Camera-intrinsics","page":"Rendering","title":"Camera intrinsics","text":"","category":"section"},{"location":"rendering/","page":"Rendering","title":"Rendering","text":"CameraIntrinsics is used to project from pixel space to camera space.","category":"page"},{"location":"rendering/","page":"Rendering","title":"Rendering","text":"CameraIntrinsics","category":"page"},{"location":"rendering/#NerfUtils.CameraIntrinsics","page":"Rendering","title":"NerfUtils.CameraIntrinsics","text":"Camera intrinsics for projecting from pixel to camera space.\n\nProjection is done as follows: ((x, y) .- principal) ./ focal. Followed by undistortion if any.\n\nArguments:\n\ndistortion::Maybe{SVector{4, Float32}}: If no distortion, then nothing.\nfocal::SVector{2, Float32}: Focal length in (fx, fy) format.\nprincipal::SVector{2, Float32}: Principal point in (cx, cy) format.   Normalized by the resolution (in [0, 1] range)\nresolution::SVector{2, UInt32}: Resolution in (width, height) format.\n\n\n\n\n\n","category":"type"},{"location":"rendering/#CameraKeyframe","page":"Rendering","title":"CameraKeyframe","text":"","category":"section"},{"location":"rendering/","page":"Rendering","title":"Rendering","text":"To smoothly transform camera from one position to another, use NerfUtils.CameraKeyframe. Used in Video Mode in NerfGUI.jl.","category":"page"},{"location":"rendering/","page":"Rendering","title":"Rendering","text":"NerfUtils.CameraKeyframe\nNerfUtils.spline","category":"page"},{"location":"rendering/#NerfUtils.CameraKeyframe","page":"Rendering","title":"NerfUtils.CameraKeyframe","text":"Camera pose described by a quaternion q and position t.\n\n\n\n\n\n","category":"type"},{"location":"rendering/#NerfUtils.spline","page":"Rendering","title":"NerfUtils.spline","text":"spline(\n    t::Float32,\n    k0::CameraKeyframe, k1::CameraKeyframe,\n    k2::CameraKeyframe, k3::CameraKeyframe)\n\nCubic B-spline between 4 CameraKeyframes. Vary t from [0, 1] to compute positions along a spline from k0 to k3.\n\n\n\n\n\n","category":"function"},{"location":"mlp/#MLP-components","page":"MLP","title":"MLP components","text":"","category":"section"},{"location":"mlp/#Layers","page":"MLP","title":"Layers","text":"","category":"section"},{"location":"mlp/","page":"MLP","title":"MLP","text":"Dense layer can be used to construct MLP. Its parameters are handled explicitly, meaning after instantiation d = Dense(1=>2), parameters are obtained with θ = NerfUtils.init(d, Backend). Where you pass one of the supported Backends to initialize the model directly on the device.","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"You can then pass inputs to the layer y = d(x, θ).","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"Chain can be used to stack multiple dense layers. Its parameters are handled in the same manner:","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"c = Chain(Dense(1=>2), Dense(2=>1))\nθ = NerfUtils.init(c, Backend)\n\nx = ...\ny = c(x, θ)","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"Dense\nNerfUtils.init(::Dense, Backend)\nNerfUtils.reset!(::Dense, θ)\nChain\nNerfUtils.init(::Chain, Backend)\nNerfUtils.reset!(::Chain, θ)","category":"page"},{"location":"mlp/#NerfUtils.Dense","page":"MLP","title":"NerfUtils.Dense","text":"function Dense(\n    mapping::Pair{Int64, Int64}, activation::F = identity,\n) where F\n\nRegular dense layer with activation.\n\n\n\n\n\n","category":"type"},{"location":"mlp/#NerfUtils.init-Tuple{Dense, Any}","page":"MLP","title":"NerfUtils.init","text":"init(d::Dense, kab)\n\nCreate parameters for the Dense layer on the given backend kab.\n\n\n\n\n\n","category":"method"},{"location":"mlp/#NerfUtils.reset!-Tuple{Dense, Any}","page":"MLP","title":"NerfUtils.reset!","text":"reset!(::Dense, θ)\n\nReinitialize parameters θ in-place.\n\n\n\n\n\n","category":"method"},{"location":"mlp/#NerfUtils.Chain","page":"MLP","title":"NerfUtils.Chain","text":"Chain(layers...)\n\nSequentially chain multiple layers.\n\n\n\n\n\n","category":"type"},{"location":"mlp/#NerfUtils.init-Tuple{Chain, Any}","page":"MLP","title":"NerfUtils.init","text":"init(c::Chain, kab)\n\nCreate parameters for the Chain on the given backend kab.\n\n\n\n\n\n","category":"method"},{"location":"mlp/#NerfUtils.reset!-Tuple{Chain, Any}","page":"MLP","title":"NerfUtils.reset!","text":"reset!(c::Chain, θ)\n\nReinitialize chain parameters in-place.\n\n\n\n\n\n","category":"method"},{"location":"mlp/#Optimizer","page":"MLP","title":"Optimizer","text":"","category":"section"},{"location":"mlp/","page":"MLP","title":"MLP","text":"There's only one optimizer available - Adam. It handles parameters that are either tuples (or named tuples) or plain arrays.","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"c = Chain(Dense(1 => 2), Dense(2 => 1))\nθ = NerfUtils.init(c, Backend)\nopt = Adam(Backend, θ; lr=1f-3)","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"After computing gradients ∇, applying the update rule can be done with NerfUtils.step! function.","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"NerfUtils.step!(opt, θ, ∇; dispose=true) # Free immediately gradient memory afterwards.\nNerfUtils.step!(opt, θ, ∇; dispose=false) # Do not free.","category":"page"},{"location":"mlp/","page":"MLP","title":"MLP","text":"Adam\nNerfUtils.reset!(::Adam)\nNerfUtils.step!(::Adam, θ, ∇; dispose::Bool)","category":"page"},{"location":"mlp/#NerfUtils.Adam","page":"MLP","title":"NerfUtils.Adam","text":"Adam(kab, θ; kwargs...)\n\nAdam optimizer.\n\nθ must be either plain array or a tuple (or named tuple).\n\n\n\n\n\n","category":"type"},{"location":"mlp/#NerfUtils.reset!-Tuple{Adam}","page":"MLP","title":"NerfUtils.reset!","text":"reset!(opt::Adam)\n\nReset the optimizer state.\n\n\n\n\n\n","category":"method"},{"location":"mlp/#NerfUtils.step!-Tuple{Adam, Any, Any}","page":"MLP","title":"NerfUtils.step!","text":"step!(opt::Adam, θ, ∇; dispose::Bool)\n\nApply update rule to parameters θ with gradients ∇.\n\nArguments:\n\ndispose::Bool: Free memory taken by gradients ∇ after update.\n\n\n\n\n\n","category":"method"},{"location":"#NerfUtils.jl","page":"Home","title":"NerfUtils.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Reusable NeRF components.","category":"page"},{"location":"#Requirements","page":"Home","title":"Requirements","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Julia 1.9 or higher.\nAMD or Nvidia GPU (supported by AMDGPU.jl or CUDA.jl respectively).","category":"page"},{"location":"#Backends","page":"Home","title":"Backends","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"When using components from this library you have to pass:","category":"page"},{"location":"","page":"Home","title":"Home","text":"ROCBackend() from AMDGPU.jl package or\nCUDABackend() from CUDA.jl package","category":"page"},{"location":"","page":"Home","title":"Home","text":"to use respective GPU.","category":"page"},{"location":"encoding/#Encodings","page":"Encoding","title":"Encodings","text":"","category":"section"},{"location":"encoding/#Multiresolution-Hash-Encoding","page":"Encoding","title":"Multiresolution Hash Encoding","text":"","category":"section"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"GridEncoding implements Multiresolution Hash Encoding which can be used to encode 3D points prior to MLP.","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"Instantiate ge = GridEncoding(Backend) with a supported backend. GridEncoding handles its parameters explicitly, meaning it is up to the user to initialize and maintain them with θ = NerfUtils.init(ge).","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"To encode input coordinates x pass them along with the parameters θ:","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"# Random 3D points on the same `Backend`.\nx = adapt(Backend, rand(Float32, 3, N))\ny = ge(x, θ)","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"Note, that inputs must be in [0, 1] range, otherwise the kernel might break. GridEncoding does not check input values.","category":"page"},{"location":"encoding/#Computing-gradients","page":"Encoding","title":"Computing gradients","text":"","category":"section"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"GridEncoding defines respective chain rules for its kernels using ChainRules.jl package, meaning it supports any AD that works with them. Following examples use Zygote.jl for that.","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"Compute gradients w.r.t. θ:","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"∇ = Zygote.gradient(θ) do θ # Passing θ explicitly to the `gradient` function.\n    sum(ge(x, θ))\nend","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"To compute gradients w.r.t. θ and input x you have to pass additional input argument IG:","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"∇ = Zygote.gradient(x, θ) do x, θ\n    sum(ge(x, θ, IG))\nend\n∇[1] # Gradient w.r.t. x.\n∇[2] # Gradient w.r.t. θ.","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"It is done this way to dispatch to a different kernel that in the forward pass precomputes necessary values for the backward pass to speed things up.","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"See GridEncoding docs for the description of each argument during instantiation as you might want to configure number of levels, their resolution and feature dimensions.","category":"page"},{"location":"encoding/","page":"Encoding","title":"Encoding","text":"GridEncoding","category":"page"},{"location":"encoding/#NerfUtils.GridEncoding","page":"Encoding","title":"NerfUtils.GridEncoding","text":"function GridEncoding(\n    kab; n_dims::Int = 3, n_levels::Int = 16, scale::Float32 = 1.5f0,\n    base_resolution::Int = 16, n_features::Int = 2, hashmap_size::Int = 19,\n    align_corners::Bool = true, store_level_ids::Bool = false)\n\nMultiresolution Hash Encoding\n\nArguments:\n\nkab: Backend on which to instantiate GridEncoding.\nn_dims::Int: Number of input dimensions (e.g. for 3D points it must be 3).\nn_levels::Int: Number of levels in the grid. Higher number of levels   results in better accuracy at the expense of device memory.\nscale::Float32: By how much to scale each next level in size.\nbase_resolution::Int: Initial resolution (1st level).\nn_features::Int: Size of the features at each level.\nhashmap_size::Int: log₂ size of the level at which it will switch from   one-to-one mapping to hashing.\nalign_corners::Bool: If true then grid corners when scaling inputs   to a respective level resolution.\nstore_level_ids::Bool: If true GridEncoding will store mapping id   from each feature to its level in the grid. This allows implementing   GridEncoding parameter decay as mean(scatter(mean, θ.^2, level_ids)).   Indices are stored in Int8 type to reduce memory usage.\n\nReference:\n\nhttps://nvlabs.github.io/instant-ngp/\n\n\n\n\n\n","category":"type"}]
}
